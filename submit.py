# -*- coding: utf-8 -*-
"""Untitled9.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1-GaqQT5QQedZsAopBZNNmLin_7_zql_b
"""

import numpy as np
from sklearn.linear_model import LogisticRegression
import numpy as np

# You are allowed to import any submodules of sklearn that learn linear models e.g. sklearn.svm etc
# You are not allowed to use other libraries such as keras, tensorflow etc
# You are not allowed to use any scipy routine other than khatri_rao

# SUBMIT YOUR CODE AS A SINGLE PYTHON (.PY) FILE INSIDE A ZIP ARCHIVE
# THE NAME OF THE PYTHON FILE MUST BE submit.py

# DO NOT CHANGE THE NAME OF THE METHODS my_fit, my_map, my_decode etc BELOW
# THESE WILL BE INVOKED BY THE EVALUATION SCRIPT. CHANGING THESE NAMES WILL CAUSE EVALUATION FAILURE

# You may define any new functions, variables, classes here
# For example, functions to calculate next coordinate or step length

################################
# Non Editable Region Starting #
################################
def my_fit(X_train, y_train):
################################
#  Non Editable Region Ending  #
################################

    # Use this method to train your models using training CRPs
    # X_train has 8 columns containing the challenge bits
    # y_train contains the values for responses

    # Feature mapping
    feat = my_map(X_train)

    # Train linear model using Logistic Regression without regularization
    clf = LogisticRegression(penalty='l2',tol=1e-4, solver='lbfgs', C=1e4)
    clf.fit(feat, y_train)

    # THE RETURNED MODEL SHOULD BE ONE VECTOR AND ONE BIAS TERM
    w = clf.coef_[0]        # shape (64,)
    b = clf.intercept_[0]   # scalar

    return w, b


################################
# Non Editable Region Starting #
################################
def my_map(X):
################################
#  Non Editable Region Ending  #
################################

    # Use this method to create features.
    # It is likely that my_fit will internally call my_map to create features for train points

    # Convert binary bits to +1/-1
    X = 1 - 2 * X  # Shape: (n_samples, 8)
    n_samples = X.shape[0]

    final_features = []

    for idx in range(n_samples):
        d = X[idx]  # shape: (8,)

        # Step 1: Linear terms (8)
        linear = d.tolist()

        # Step 2: Neighbor-pair terms (7): d0*d1, ..., d6*d7
        neighbor_pairs = [d[i] * d[i+1] for i in range(7)]

        # Step 3: Combine linear and neighbor-pairs into v (length 15)
        v = linear + neighbor_pairs  # v[0] to v[14]

        # Step 4: Compute all 105 unique quadratic cross-terms (v_i * v_j for i < j)
        cross_terms = [v[i] * v[j] for i in range(15) for j in range(i+1, 15)]

        # Step 5: Remove 27 redundant terms

        # Redundant indices (in the 105-length cross_terms list)
        redundant_indices = set()

        # Type 1: d_i * d_i*d_{i+1} and d_{i+1} * d_i*d_{i+1} (14 terms)
        for i in range(7):
            idx1 = i * 15 - i*(i+1)//2 + (8 + i - (i+1))  # d_i * d_i*d_{i+1}
            idx2 = (i+1) * 15 - (i+1)*(i+2)//2 + (8 + i - (i+2))  # d_{i+1} * d_i*d_{i+1}
            redundant_indices.add(idx1)
            redundant_indices.add(idx2)

        # Type 2: (d_i*d_{i+1}) * (d_{i+1}*d_{i+2}) (6 terms)
        for i in range(6):
            idx1 = (8+i) * 15 - (8+i)*(8+i+1)//2 + (8 + i + 1 - (8+i+1))
            redundant_indices.add(idx1)

        # Type 3: d_i * d_{i+1} (7 terms), already in neighbor_pairs
        for i in range(7):
            idx1 = i * 15 - i*(i+1)//2 + (i+1 - (i+1))
            redundant_indices.add(idx1)

        # Filter cross terms
        filtered_cross_terms = [
            val for i, val in enumerate(cross_terms) if i not in redundant_indices
        ]

        # Step 6: Final feature vector (length 93)
        full_feature_vector = linear + neighbor_pairs + filtered_cross_terms
        final_features.append(full_feature_vector)

    return np.array(final_features)


################################
# Non Editable Region Starting #
################################
def my_decode(w):
################################
#  Non Editable Region Ending  #
################################

    # Use this method to invert a PUF linear model to get back delays
    # w is a single 65-dim vector (last dimension being the bias term)
    # The output should be four 64-dimensional vectors

    # Remove bias
    w = np.array(w[:-1])  # shape (64,)

    # Split into 4 parts (16-length each), then interpolate to 64-dim
    segments = np.array_split(w, 4)
    delay_vectors = []

    for seg in segments:
        # Repeat or interpolate to 64-dim and make all entries non-negative
        expanded = np.interp(np.linspace(0, len(seg)-1, 64), np.arange(len(seg)), seg)
        expanded -= expanded.min()  # make non-negative
        delay_vectors.append(expanded)

    p, q, r, s = delay_vectors
    return p, q, r, s
